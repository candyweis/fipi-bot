# -*- coding: utf-8 -*-
"""
–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –±–æ—Ç–∞ - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö
"""
import os
import asyncio
import logging
from datetime import datetime, timedelta
from telegram.ext import ContextTypes
from parser import TaskIdExtractor
from database import store, save_store, save_parsing_result
from utils import subj_by_url, get_current_count, split_message
from keyboards import kb_main_reply

log = logging.getLogger("FIPI-Bot")

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä—Å–∏–Ω–≥–æ–≤
active_auto_parsing = set()

async def periodic_check(context: ContextTypes.DEFAULT_TYPE):
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É"""
    log.info("üîç –ù–∞—á–∞–ª–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏...")
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ URL –∏–∑ –ø–æ–¥–ø–∏—Å–æ–∫
    all_urls = set()
    for user_urls in store["subscriptions"].values():
        all_urls.update(user_urls)
    if not all_urls:
        log.info("üì≠ –ù–µ—Ç –ø–æ–¥–ø–∏—Å–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
        return
    log.info(f"üîç –ü—Ä–æ–≤–µ—Ä—è—é {len(all_urls)} –ø—Ä–µ–¥–º–µ—Ç–æ–≤...")
    for url in all_urls:
        try:
            await check_url_changes(context, url)
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ URL {url}: {e}")
    log.info("‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

async def check_url_changes(context: ContextTypes.DEFAULT_TYPE, url: str):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ URL"""
    subject_name = subj_by_url(url)
    try:
        log.info(f"üìä –ü—Ä–æ–≤–µ—Ä—è—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞–Ω–∏–π –¥–ª—è {subject_name}")
        try:
            current_count = await asyncio.to_thread(get_current_count, url)
        except AttributeError:
            loop = asyncio.get_event_loop()
            current_count = await loop.run_in_executor(None, get_current_count, url)
        if current_count is None:
            log.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è {subject_name}")
            return
        previous_count = store["last_counts"].get(url)
        if previous_count is None:
            log.info(f"üìù –ü–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ {subject_name}: {current_count} –∑–∞–¥–∞–Ω–∏–π")
            store["last_counts"][url] = current_count
            save_store(store)
            return
        if previous_count != current_count:
            log.info(f"üö® –ò–ó–ú–ï–ù–ï–ù–ò–ï –û–ë–ù–ê–†–£–ñ–ï–ù–û! {subject_name}: {previous_count} ‚Üí {current_count}")
            if url in active_auto_parsing:
                log.info(f"‚è≥ –ü–∞—Ä—Å–∏–Ω–≥ –¥–ª—è {subject_name} —É–∂–µ –∞–∫—Ç–∏–≤–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                return
            active_auto_parsing.add(url)
            try:
                await notify_quantity_change(context, url, previous_count, current_count)
                await start_automatic_parsing(context, url, current_count)
            finally:
                active_auto_parsing.discard(url)
        else:
            log.debug(f"üìä {subject_name}: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ({current_count})")
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è {subject_name}: {e}")

async def notify_quantity_change(context: ContextTypes.DEFAULT_TYPE, url: str,
                                 old_count: int, new_count: int):
    """–£–≤–µ–¥–æ–º–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–¥–∞–Ω–∏–π"""
    subject_name = subj_by_url(url)
    subscribers = []
    for chat_id, urls in store["subscriptions"].items():
        if url in urls:
            subscribers.append(chat_id)
    if not subscribers:
        return
    change_type = "üìà –£–≤–µ–ª–∏—á–∏–ª–æ—Å—å" if new_count > old_count else "üìâ –£–º–µ–Ω—å—à–∏–ª–æ—Å—å"
    difference = abs(new_count - old_count)
    message = (f"üîî –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π!\n\n"
               f"üìö {subject_name}\n"
               f"{change_type} –Ω–∞ {difference}\n"
               f"üìä –ë—ã–ª–æ: {old_count} ‚Üí –°—Ç–∞–ª–æ: {new_count}\n\n"
               f"ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞—é –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π...")
    log.info(f"üì¢ –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π {len(subscribers)} –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º")
    for chat_id in subscribers:
        try:
            await context.bot.send_message(
                chat_id=int(chat_id),
                text=message,
                reply_markup=kb_main_reply()
            )
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {chat_id}: {e}")

async def start_automatic_parsing(context: ContextTypes.DEFAULT_TYPE, url: str, current_count: int):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞"""
    from queue_manager import queue_parsing_task
    subject_name = subj_by_url(url)
    log.info(f"üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {subject_name}")
    class AutoQuery:
        def __init__(self):
            self.from_user = type('User', (), {'id': 'auto'})()
        async def edit_message_text(self, text, reply_markup=None):
            log.info(f"ü§ñ –ê–≤—Ç–æ–ø–∞—Ä—Å–∏–Ω–≥: {text}")
    auto_query = AutoQuery()
    fake_context = type('Context', (), {
        'user_data': {'cmp_map': {'0': url}}
    })()
    try:
        await queue_parsing_task(
            auto_query, fake_context, "cmp_0",
            "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥",
            lambda q, c, r, u: auto_parsing_callback(q, c, r, u, context),
            is_auto=True
        )
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {subject_name}: {e}")

async def auto_parsing_callback(query, context_unused, result, url, bot_context):
    """Callback –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    try:
        current_ids, added, removed = result
        timestamp = datetime.now().isoformat()
        current_count = len(current_ids)
        store["last_counts"][url] = current_count
        save_store(store)
        if added or removed:
            await notify_id_changes(bot_context, url, added, removed, len(current_ids))
        else:
            await notify_no_id_changes(bot_context, url, len(current_ids))
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ callback –∞–≤—Ç–æ–ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è {url}: {e}")

async def notify_id_changes(context: ContextTypes.DEFAULT_TYPE, url: str,
                           added: set, removed: set, total_count: int):
    """–£–≤–µ–¥–æ–º–ª—è–µ—Ç –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö ID"""
    subject_name = subj_by_url(url)
    timestamp = datetime.now().isoformat()
    subscribers = []
    for chat_id, urls in store["subscriptions"].items():
        if url in urls:
            subscribers.append(chat_id)
    if not subscribers:
        return
    change_parts = []
    if added:
        change_parts.append(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ: {len(added)} ID")
    if removed:
        change_parts.append(f"‚ûñ –£–¥–∞–ª–µ–Ω–æ: {len(removed)} ID")
    change_text = "\n".join(change_parts)
    main_message = (f"‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!\n\n"
                    f"üìö {subject_name}\n"
                    f"üÜî –í—Å–µ–≥–æ ID: {total_count}\n\n"
                    f"üîç –ù–ê–ô–î–ï–ù–´ –ò–ó–ú–ï–ù–ï–ù–ò–Ø:\n{change_text}\n\n"
                    f"üìÑ –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ —Ñ–∞–π–ª–µ ‚Üì")
    log.info(f"üìä –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏–π {len(subscribers)} –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º")
    for chat_id in subscribers:
        try:
            messages = split_message(main_message)
            for msg in messages:
                await context.bot.send_message(
                    chat_id=int(chat_id),
                    text=msg,
                    reply_markup=kb_main_reply()
                )
            await send_auto_changes_file(context, chat_id, url, added, removed, timestamp)
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {chat_id}: {e}")

async def notify_no_id_changes(context: ContextTypes.DEFAULT_TYPE, url: str, total_count: int):
    """–£–≤–µ–¥–æ–º–ª—è–µ—Ç –æ–± –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π ID"""
    subject_name = subj_by_url(url)
    subscribers = []
    for chat_id, urls in store["subscriptions"].items():
        if url in urls:
            subscribers.append(chat_id)
    if not subscribers:
        return
    message = (f"‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω!\n\n"
               f"üìö {subject_name}\n"
               f"üÜî –í—Å–µ–≥–æ ID: {total_count}\n\n"
               f"‚ÑπÔ∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞–Ω–∏–π –∏–∑–º–µ–Ω–∏–ª–æ—Å—å, –Ω–æ —Å–æ—Å—Ç–∞–≤ ID –æ—Å—Ç–∞–ª—Å—è –ø—Ä–µ–∂–Ω–∏–º")
    for chat_id in subscribers:
        try:
            await context.bot.send_message(
                chat_id=int(chat_id),
                text=message,
                reply_markup=kb_main_reply()
            )
        except Exception as e:
            log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è {chat_id}: {e}")

async def send_auto_changes_file(context: ContextTypes.DEFAULT_TYPE, chat_id: str,
                                url: str, added: set, removed: set, timestamp: str):
    """–°–æ–∑–¥–∞–µ—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏ ID"""
    try:
        subject_name = subj_by_url(url)
        safe_timestamp = timestamp.replace(':', '-').replace('.', '_')
        filename = f"auto_changes_{url.split('=')[-1]}_{safe_timestamp}.txt"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"ü§ñ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –ò–ó–ú–ï–ù–ï–ù–ò–ô\n")
            f.write(f"–ü—Ä–µ–¥–º–µ—Ç: {subject_name}\n")
            f.write(f"–í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"=" * 50 + "\n\n")
            if added:
                f.write(f"‚ûï –î–û–ë–ê–í–õ–ï–ù–´ ID ({len(added)}):\n")
                f.write("-" * 30 + "\n")
                for task_id in sorted(added):
                    f.write(f"{task_id}\n")
                f.write("\n")
            if removed:
                f.write(f"‚ûñ –£–î–ê–õ–ï–ù–´ ID ({len(removed)}):\n")
                f.write("-" * 30 + "\n")
                for task_id in sorted(removed):
                    f.write(f"{task_id}\n")
                f.write("\n")
            f.write(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:\n")
            f.write(f"–î–æ–±–∞–≤–ª–µ–Ω–æ: {len(added)} ID\n")
            f.write(f"–£–¥–∞–ª–µ–Ω–æ: {len(removed)} ID\n")
            f.write(f"–û–±—â–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {len(added) - len(removed):+d} ID\n")
        with open(filename, "rb") as f:
            await context.bot.send_document(
                chat_id=int(chat_id),
                document=f,
                filename=filename,
                caption=f"ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π\nüìö {subject_name}"
            )
        try:
            os.remove(filename)
        except Exception as e:
            log.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {filename}: {e}")
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è {chat_id}: {e}")

async def cleanup_old_data():
    """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ"""
    try:
        cutoff_date = datetime.now() - timedelta(days=30)
        cleaned_count = 0
        for url in list(store.get("historical_ids", {}).keys()):
            history = store["historical_ids"][url]
            if history:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É)
                sorted_history = sorted(history, key=lambda x: datetime.fromisoformat(x["timestamp"]), reverse=True)
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π (—Å–∞–º—ã–π —Å–≤–µ–∂–∏–π)
                filtered_history = [sorted_history[0]]
                # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ, –µ—Å–ª–∏ –Ω–µ —Å—Ç–∞—Ä—à–µ cutoff
                for record in sorted_history[1:]:
                    if datetime.fromisoformat(record["timestamp"]) > cutoff_date:
                        filtered_history.append(record)
                if len(filtered_history) != len(history):
                    store["historical_ids"][url] = filtered_history
                    cleaned_count += len(history) - len(filtered_history)
        from database import clean_old_parsing_cache
        clean_old_parsing_cache()
        empty_subscriptions = []
        for chat_id, urls in store.get("subscriptions", {}).items():
            if not urls:
                empty_subscriptions.append(chat_id)
        for chat_id in empty_subscriptions:
            del store["subscriptions"][chat_id]
        if empty_subscriptions:
            log.info(f"üßπ –£–¥–∞–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏: {len(empty_subscriptions)}")
        save_store(store)
        log.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —É–¥–∞–ª–µ–Ω–æ {cleaned_count} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π")
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

async def daily_cleanup(context: ContextTypes.DEFAULT_TYPE):
    """–ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    log.info("üßπ –ó–∞–ø—É—Å–∫ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
    try:
        await cleanup_old_data()
        temp_files_removed = 0
        for filename in os.listdir("."):
            if (filename.startswith("progress_") or
                filename.startswith("auto_changes_") or
                filename.startswith("cached_ids_") or
                filename.startswith("ids_") or
                filename.startswith("changes_")):
                try:
                    file_age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(filename))
                    if file_age.total_seconds() > 3600:  # –°—Ç–∞—Ä—à–µ —á–∞—Å–∞
                        os.remove(filename)
                        temp_files_removed += 1
                except Exception as e:
                    log.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {filename}: {e}")
        if temp_files_removed > 0:
            log.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {temp_files_removed}")
        total_subscriptions = sum(len(urls) for urls in store.get("subscriptions", {}).values())
        total_users = len(store.get("subscriptions", {}))
        log.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏:")
        log.info(f" üë• –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {total_users}")
        log.info(f" üìö –ü–æ–¥–ø–∏—Å–æ–∫: {total_subscriptions}")
        log.info(f" üóÇÔ∏è URLs –≤ –∏—Å—Ç–æ—Ä–∏–∏: {len(store.get('historical_ids', {}))}")
        log.info(f" üíæ –†–∞–∑–º–µ—Ä –∫—ç—à–∞: {len(store.get('recent_parsing', {}))}")
    except Exception as e:
        log.error(f"‚ùå –û—à–∏–±–∫–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏: {e}")
